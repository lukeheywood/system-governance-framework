# 0.1 — Define the Object of Governance

This section establishes **what governance applies to**, before any design, build, deployment, or operational activity is permitted.

No subsequent governance phase is valid unless this section has been completed and fixed.

---

## 0.1.1 Why this exists

### Purpose

The purpose of this section is to **require explicit definition of the object being governed**, before any decisions are made about design, implementation, operation, or oversight.

Governance cannot operate over an undefined or shifting object.

If the object of governance is not fixed in advance:

* responsibility cannot be assigned coherently
* authority cannot be exercised legitimately
* scope will drift under operational pressure
* enforcement boundaries will collapse retroactively

This section exists to **prevent governance from being reconstructed after failure**.

It therefore **precedes all other phases** and is **non-optional**.

---

## 0.1.2 Definition — Object of Governance

### Meaning

For the purposes of this framework, **the object of governance is the AI-influenced system as a whole**, not any individual component in isolation.

The object of governance is defined as:

> **The complete socio-technical system whose behaviour, outputs, or decisions are materially influenced by AI-mediated processes.**

This includes all elements that contribute to, constrain, interpret, or act upon AI-mediated behaviour.

This is a **binding definition**, not an illustrative one.

---

### Included by definition

The object of governance **includes**, at minimum:

* AI models (trained, fine-tuned, or third-party)
* Decision logic, orchestration, and control flows
* Data sources, transformations, and feedback loops
* Interfaces through which outputs are surfaced or acted upon
* Human operators involved in supervision, override, or interpretation
* Downstream systems that execute or rely on AI-influenced outputs
* Policies, thresholds, and configuration that shape behaviour at runtime
* Monitoring, logging, and alerting mechanisms tied to system behaviour

Inclusion is determined by **influence**, not ownership, implementation location, or contractual boundary.

---

### Explicit exclusions

Components or processes may be excluded **only if it can be demonstrated that they exert no material influence** on system behaviour, outputs, or decisions.

Assertions of exclusion are insufficient.

If a component:

* constrains inputs
* shapes outputs
* gates execution
* alters interpretation
* receives or propagates AI-derived signals

it is **in scope**, regardless of how it is labelled.

---

## 0.1.3 Scope Implications

### Meaning

This subsection specifies **what necessarily follows** from the definition above.

Once the object of governance is defined:

1. **Scope propagates transitively**
   Any component, interface, dataset, or actor that the system depends on, or that depends on the system’s outputs, is within scope to the extent of that influence.

2. **Influence cannot be disowned**
   If AI materially affects an outcome, responsibility for that outcome cannot be excluded by organisational charts, vendor boundaries, or abstraction layers.

3. **Partial governance is invalid**
   Governing only a model, tool, or deployment surface while excluding the system that operationalises it constitutes a governance failure.

4. **Human involvement does not remove scope**
   The presence of a human “in the loop” does not exempt a system from governance.
   It simply adds additional governed actors and interfaces.

---

### Constraint

Once AI influence exists within a system:

> **Governance applies to the entire system within the radius of that influence.**

No subsequent phase may narrow scope without demonstrating the complete absence of influence.

This constraint is **structural** and **non-negotiable**.
